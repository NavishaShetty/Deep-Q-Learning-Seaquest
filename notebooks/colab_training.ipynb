{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning Galaxian - Google Colab Setup\n",
    "\n",
    "This notebook sets up and runs the DQN training experiments on Google Colab.\n",
    "\n",
    "This notebook uses GPU. Make sure to enable GPU acceleration:\n",
    "- Go to Runtime → Change runtime type\n",
    "- Select GPU as hardware accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GitHub repository\n",
    "!git clone https://github.com/YOUR_USERNAME/deep-q-learning-galaxian.git\n",
    "%cd deep-q-learning-galaxian\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q gymnasium[atari]\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q ale-py numpy matplotlib pandas jupyter\n",
    "\n",
    "print(\"All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check installations\n",
    "import sys\n",
    "sys.path.insert(0, '/content/deep-q-learning-galaxian')\n",
    "\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "\n",
    "# Test environment\n",
    "env = gym.make(\"ALE/Galaxian-v5\")\n",
    "state, info = env.reset()\n",
    "print(f\"\\nGymnasium Galaxian environment loaded!\")\n",
    "print(f\"State shape: {state.shape}\")\n",
    "print(f\"Action space: {env.action_space.n} actions\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Run Baseline Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline training\n",
    "!python experiments/baseline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Run Bellman Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bellman parameter experiments\n",
    "!python experiments/bellman_exp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Run Policy Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run policy exploration experiments\n",
    "!python experiments/policy_exp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Run Decay Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run exploration decay experiments\n",
    "!python experiments/decay_exp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Check what results were saved\n",
    "results_dirs = [\n",
    "    'results/baseline',\n",
    "    'results/bellman',\n",
    "    'results/policy',\n",
    "    'results/decay'\n",
    "]\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for results_dir in results_dirs:\n",
    "    if os.path.exists(results_dir):\n",
    "        files = os.listdir(results_dir)\n",
    "        print(f\"\\n{results_dir}:\")\n",
    "        for f in files:\n",
    "            print(f\"  - {f}\")\n",
    "    else:\n",
    "        print(f\"\\n{results_dir}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Load and Analyze Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline metrics\n",
    "baseline_metrics = pd.read_csv('results/baseline/metrics.csv')\n",
    "\n",
    "print(\"Baseline Training Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total episodes: {len(baseline_metrics)}\")\n",
    "print(f\"\\nReward Statistics:\")\n",
    "print(f\"  Mean reward: {baseline_metrics['reward'].mean():.2f}\")\n",
    "print(f\"  Max reward: {baseline_metrics['reward'].max():.2f}\")\n",
    "print(f\"  Min reward: {baseline_metrics['reward'].min():.2f}\")\n",
    "print(f\"\\nFinal 100-episode average:\")\n",
    "print(f\"  Avg reward: {baseline_metrics['moving_avg_reward'].iloc[-1]:.2f}\")\n",
    "print(f\"  Avg length: {baseline_metrics['moving_avg_length'].iloc[-1]:.2f}\")\n",
    "print(f\"\\nExploration:\")\n",
    "print(f\"  Final epsilon: {baseline_metrics['epsilon'].iloc[-1]:.6f}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst 5 episodes:\")\n",
    "print(baseline_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Reward over time\n",
    "axes[0, 0].plot(baseline_metrics['episode'], baseline_metrics['reward'], \n",
    "                 alpha=0.5, label='Episode Reward')\n",
    "axes[0, 0].plot(baseline_metrics['episode'], baseline_metrics['moving_avg_reward'], \n",
    "                 'r-', linewidth=2, label='Moving Average (100 ep)')\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Reward')\n",
    "axes[0, 0].set_title('Reward Over Training')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Episode length\n",
    "axes[0, 1].plot(baseline_metrics['episode'], baseline_metrics['length'], \n",
    "                 alpha=0.5, label='Episode Length')\n",
    "axes[0, 1].plot(baseline_metrics['episode'], baseline_metrics['moving_avg_length'], \n",
    "                 'r-', linewidth=2, label='Moving Average')\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Steps')\n",
    "axes[0, 1].set_title('Episode Length Over Training')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Epsilon decay\n",
    "axes[1, 0].plot(baseline_metrics['episode'], baseline_metrics['epsilon'], \n",
    "                 'g-', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Epsilon')\n",
    "axes[1, 0].set_title('Exploration Rate Decay')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Reward distribution\n",
    "axes[1, 1].hist(baseline_metrics['reward'], bins=30, alpha=0.7, \n",
    "                 edgecolor='black', color='blue')\n",
    "axes[1, 1].set_xlabel('Episode Reward')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Reward Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/baseline/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training curves saved to results/baseline/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Compare Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary results from experiments\n",
    "print(\"\\nEXPERIMENT RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Bellman experiments\n",
    "if os.path.exists('results/bellman/summary.csv'):\n",
    "    bellman_summary = pd.read_csv('results/bellman/summary.csv')\n",
    "    print(\"\\nBellman Parameter Experiments:\")\n",
    "    print(bellman_summary.to_string(index=False))\n",
    "\n",
    "# Policy experiments\n",
    "if os.path.exists('results/policy/summary.csv'):\n",
    "    policy_summary = pd.read_csv('results/policy/summary.csv')\n",
    "    print(\"\\nPolicy Exploration Experiments:\")\n",
    "    print(policy_summary.to_string(index=False))\n",
    "\n",
    "# Decay experiments\n",
    "if os.path.exists('results/decay/summary.csv'):\n",
    "    decay_summary = pd.read_csv('results/decay/summary.csv')\n",
    "    print(\"\\nExploration Decay Experiments:\")\n",
    "    print(decay_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results for download\n",
    "import shutil\n",
    "\n",
    "# Create zip file\n",
    "shutil.make_archive('dqn_results', 'zip', 'results')\n",
    "\n",
    "# Download results\n",
    "from google.colab import files\n",
    "files.download('dqn_results.zip')\n",
    "\n",
    "print(\"Results zipped and ready for download!\")\n",
    "print(\"  File: dqn_results.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Commit Results to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push results back to GitHub\n",
    "!git config user.name \"NavishaShetty\"\n",
    "!git config user.email \"shetty.navi@northeastern.edu\"\n",
    "\n",
    "# Add results\n",
    "!git add results/\n",
    "\n",
    "# Commit\n",
    "!git commit -m \"Add training results from Google Colab\"\n",
    "\n",
    "# Push to GitHub (requires authentication)\n",
    "# !git push origin main\n",
    "\n",
    "print(\"✓ Results committed (not pushed - requires authentication)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DQN_Seaquest_Training",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
